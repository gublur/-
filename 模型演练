                             GPT技术演练
1.GPT系列模型发展历程

 ---》gpt-1(1.1亿参数）
  》decode-only transformer架构
  》预训练后针对特定任务微调

 ---》》gpt-2（15亿参数）
   》将任务形式统一为单词预测（Pr(ouput|input,task)
   》预训练与下游任务一致
   》使用提示进行无监督任务求解
   》初步尝试规模扩展

 ---》》》gpt-3(1750亿参数）
   》涌现出上下文能力

 ---》》》>codex
    》代码数据训练
    》推理与代码合成能力

 instructGPT
    》大语言模型与人类价值观对齐，提出RLHF算法

  ---》》》》gpt-4
    》推理能力显著提升，建立可预测训练框架,可支持多模态信息大模型

  ---》》》》gpt-4o
     》原生态的多模态模型，综合模态能力显著，支持统一处理和输出文本，音频，图片，视频信息

   》推理大模型：o-series
   推理任务上能力大幅度提升，长思维链推理能力
2.Deepseek系列模型演历程
  
